{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель занятия — рассмотреть этапы подготовки данных для моделей машинного обучения.\n",
    "\n",
    "Подготовка данных для алгоритмов МО включает:\n",
    "\n",
    "исследование данных;\n",
    "очистку и исправление данных;\n",
    "разделение выборки на тренировочную и тестовую;\n",
    "определение видов признаков;\n",
    "предобработку признаков;\n",
    "создание новых признаков;\n",
    "отбор признаков.\n",
    "Давайте рассмотрим каждый из этих этапов.\n",
    "\n",
    "1. ИССЛЕДОВАНИЕ ДАННЫХ\n",
    "\n",
    "Исследование данных (EDA) позволяет понять данные, выявить скрытые связи и паттерны, определить выбросы и пропущенные значения, а также принять решение о необходимости дополнительной предобработки данных.\n",
    "\n",
    "EDA может включать в себя следующие шаги:\n",
    "\n",
    "Визуализация данных — создание графиков и диаграмм, чтобы выявить скрытые закономерности и паттерны.\n",
    "Изучение связей между различными переменными и определение того, какие из них сильно влияют на другие.\n",
    "В результате исследования мы лучше понимаем данные, что помогает выбрать подходящую модель МО, провести более эффективную предобработку данных и принять правильные решения на этапе обучения модели.\n",
    "\n",
    "2. ОЧИСТКА И ИСПРАВЛЕНИЕ ДАННЫХ\n",
    "\n",
    "Очистка данных — это процесс предварительной обработки данных, направленный на удаление или исправление ошибочных, неактуальных, неполных, повреждённых, дублированных или неправильно форматированных данных. Это делается, чтобы улучшить качество и точность модели машинного обучения.\n",
    "\n",
    "Вот некоторые методы очистки данных в МО:\n",
    "\n",
    "Удаление дубликатов.\n",
    "Исправление ошибок. В данных могут быть опечатки или неверные значения. Такие ошибки можно исправить с помощью автоматических методов, например через автоисправление опечаток.\n",
    "3. РАЗДЕЛЕНИЕ ВЫБОРКИ НА ТРЕНИРОВОЧНУЮ И ТЕСТОВУЮ\n",
    "\n",
    "Разбиение выборки на тренировочную (обучающую) и тестовую — один из ключевых этапов МО, который позволяет оценить качество работы модели на новых данных. При этом часть данных используется для обучения модели (обучающая выборка), а оставшаяся часть — для проверки её качества (тестовая выборка). Благодаря такому разделению можно убедиться, что модель обладает высокой точностью на новых данных и не переобучена на имеющейся выборке.\n",
    "\n",
    "Важно! Разделить выборку на тренировочную и тестовую нужно до начала обработки данных и обучения модели.\n",
    "\n",
    "Также необходимо убедиться, что выборки не содержат дублирующихся или повторяющихся данных и что разделение происходит случайным образом или с учётом определённого критерия. Это поможет избежать смещения в оценке качества модели.\n",
    "\n",
    "Существует несколько способов разделения выборки на тренировочную, валидационную (выборка для настройки гиперпараметров модели) и тестовую. Факторы, которые можно учитывать при выборе метода разбиения:\n",
    "\n",
    "Размер выборки. Чтобы точнее оценить модель на небольших выборках, может быть лучше использовать кросс-валидацию (перекрёстную проверку).\n",
    "Целевой признак. Если целевой признак несбалансированный, необходимо убедиться, что он представлен в обеих выборках.\n",
    "Распределение признаков. Если признаки имеют разное распределение в тренировочной и тестовой выборках, это может привести к переобучению или недообучению модели.\n",
    "Временные ряды. При анализе временных рядов необходимо учитывать хронологический порядок данных и использовать методы, которые могут учитывать этот фактор.\n",
    "Доступность данных. Иногда сложно получить достаточное количество данных, чтобы построить отдельные тренировочную и тестовую выборки. В этом случае можно максимизировать использование имеющихся данных с помощью специальных методов.\n",
    "Выбор метода разбиения выборки зависит от конкретной задачи и доступных данных. Чтобы найти наилучший вариант, могут потребоваться эксперименты с различными методами.\n",
    "\n",
    "Наиболее распространённые эксперименты:\n",
    "\n",
    "Разбиение на обучающую, валидационную и тестовую выборки в пропорции 60–20–20 (или любой другой на выбор). Разбиение реализовано в функциях train_test_split и test_train_split библиотеки sklearn.\n",
    "Использование кросс-валидации, при которой данные разбиваются на несколько равных частей (фолдов), и каждая часть используется в качестве тестовой выборки, а остальные части объединяются и используются для обучения модели. Кросс-валидация реализована в функциях KFold, StratifiedKFold, TimeSeriesSplit библиотеки sklearn.\n",
    "Однократное разбиение на обучающую и тестовую выборки, а затем использование внутренней кросс-валидации на обучающей выборке для подбора параметров модели и оценки её качества на валидационной выборке.\n",
    "Разбиение на обучающую, валидационную и тестовую выборки с помощью временных рядов, когда данные разбиваются на обучающую и тестовую выборки в хронологическом порядке, а затем выборка для валидации формируется из части обучающей выборки, расположенной в более раннем временном периоде, чем тестовая выборка.\n",
    "Кроме того, для некоторых задач может быть полезно использовать стратифицированное разбиение, когда сохраняется пропорция классов в каждой выборке, или разбиение с учётом баланса классов, когда классы распределяются между выборками с учетом их дисбаланса.\n",
    "\n",
    "4. ОПРЕДЕЛЕНИЕ ВИДОВ ПРИЗНАКОВ\n",
    "\n",
    "В машинном обучении существуют различные виды признаков, которые можно использовать для описания объектов или данных.\n",
    "\n",
    "Виды признаков:\n",
    "\n",
    "Категориальные признаки — признаки, которые принимают значения из определённого набора категорий или классов (цвет, тип материала и т. д.).\n",
    "Числовые признаки — признаки, которые принимают числовые значения (длина, ширина, высота, возраст и т. д.).\n",
    "Бинарные признаки — признаки, которые могут принимать только два значения (0 и 1, да или нет и т. д.).\n",
    "Текстовые признаки — признаки, которые описывают текстовые данные (заголовки новостей, описания продуктов и т. д.).\n",
    "Географические признаки — признаки, которые описывают географические данные (координаты, адреса и т. д.).\n",
    "Временные признаки — признаки, которые описывают данные, относящиеся ко времени (дата, время, длительность и т. д.).\n",
    "Работа с разными видами признаков в МО требует специфических методов, так как у каждого вида есть уникальные свойства.\n",
    "\n",
    "Категориальные признаки нуждаются в преобразовании перед использованием в модели. Для этого можно использовать, например, One-Hot Encoding или Label Encoding (определение этих методов мы рассмотрим ниже). Некоторые алгоритмы машинного обучения (деревья решений и случайный лес) могут обрабатывать категориальные признаки напрямую.\n",
    "Числовые признаки можно использовать без какой-либо специальной обработки, но нормализация и стандартизация улучшают результаты. При работе с числовыми признаками также может быть полезно создать новые признаки, например путём извлечения корня или возведения в квадрат.\n",
    "Бинарные признаки также можно использовать без специальной обработки. Однако может потребоваться обработка выбросов, так как значения могут быть ограничены только двумя значениями.\n",
    "Текстовые признаки необходимо преобразовать в числовой формат для использования в модели. Для этого можно применять, например, CountVectorizer или TF-IDF.\n",
    "\n",
    "Географические признаки можно преобразовать в числовой формат, например через координаты или почтовый индекс. При работе с географическими признаками также могут быть полезны новые признаки — расстояние между объектами или количество объектов в радиусе действия.\n",
    "Временные признаки можно использовать без специальной обработки, но также могут быть полезны новые признаки, например, день недели или время суток.\n",
    "5. ПРЕДОБРАБОТКА ПРИЗНАКОВ\n",
    "\n",
    "Предобработка признаков — это процесс подготовки данных перед применением модели МО. Цель предобработки — привести данные к такому виду, который будет оптимальным для обучения модели и получения максимальной точности предсказаний.\n",
    "\n",
    "Предобработка признаков позволяет увеличить точность модели, снизить шум и сделать данные более понятными для алгоритма.\n",
    "\n",
    "Этапы предобработки признаков в машинном обучении:\n",
    "\n",
    "Обработка выбросов, заполнение пропущенных значений и т. д.\n",
    "Преобразование признаков — преобразование данных в числовой формат, нормализация и масштабирование признаков, преобразование категориальных признаков и т. д.\n",
    "Рассмотрим эти этапы предобработки подробнее.\n",
    "\n",
    "ОБРАБОТКА ВЫБРОСОВ\n",
    "\n",
    "Обработка выбросов — это процесс идентификации и обработки экстремальных значений (наблюдений), которые могут исказить результаты анализа и привести к ошибочным выводам.\n",
    "\n",
    "Выбросы могут возникать из-за ошибок в измерениях, аномалий в данных или других факторов.\n",
    "\n",
    "Существует несколько способов обработки выбросов.\n",
    "\n",
    "Замена выбросов на какое-то более типичное значение. Это может быть медиана, среднее или любое другое значение, которое соответствует типичным значениям признаков в выборке данных.\n",
    "\n",
    "Удаление выбросов. Важно помнить, что удаление выбросов может привести к потере информации. Поэтому решение о том, следует ли удалять выбросы, должно быть основано на конкретной задаче и анализе данных.\n",
    "\n",
    "Существует несколько способов удалить выбросы:\n",
    "\n",
    "Метод межквартильного размаха (interquartile range, IQR) основан на вычислении межквартильного размаха данных, который определяет расстояние между 25-м и 75-м процентилем данных. Затем выбросы определяются как значения, находящиеся за пределами верхнего и нижнего порогов, определяемых как  и  соответственно.\n",
    "Удаление выбросов на основе статистических критериев. Этот метод использует статистические критерии (Z-оценку или T-тест) для определения, является ли значение выбросом. Если оно превышает определённый пороговый уровень, то считается выбросом и удаляется.\n",
    "Использование робастных (устойчивых к выбросам) моделей. Робастные модели машинного обучения устойчивы к выбросам и могут работать более точно, даже если в выборке есть выбросы. Например, линейные модели, которые используют L1-регуляризацию (Lasso) или L2-регуляризацию (Ridge), могут быть более устойчивыми к выбросам, чем стандартные линейные модели.\n",
    "\n",
    "Некоторые алгоритмы машинного обучения (метод случайных деревьев, градиентный бустинг) могут учитывать выбросы, используя различные стратегии сэмплирования и ансамблирования.\n",
    "\n",
    "Проведение дополнительного исследования. Если выбросы вызваны реальными аномалиями, то они могут содержать важную информацию о данных. Поэтому может быть полезно провести дополнительное исследование, чтобы понять, почему выбросы возникли и как их можно использовать в моделировании.\n",
    "\n",
    "ЗАПОЛНЕНИЕ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ\n",
    "\n",
    "Некоторые значения могут быть пропущены или недоступны, например из-за ошибок или недоступности источника данных. Пропущенные значения можно заменить средним, медианным или модальным значением или использовать другие методы заполнения, например на основе предсказаний модели.\n",
    "\n",
    "ПРЕОБРАЗОВАНИЕ ДАННЫХ В ЧИСЛОВОЙ ФОРМАТ\n",
    "\n",
    "У некоторых признаков может быть неправильный тип данных, например, строковые данные вместо числовых. Необходимо преобразовать типы данных в правильный формат.\n",
    "\n",
    "Рассмотрим преобразование данных в числовой формат на примере признака «возраст»:\n",
    "\n",
    "ВОЗРАСТ\tВОЗРАСТ_ — NUM\n",
    "«20»\t20\n",
    "«30»\t30\n",
    "«40»\t40\n",
    "«50»\t50\n",
    "НОРМАЛИЗАЦИЯ И МАСШТАБИРОВАНИЕ ПРИЗНАКОВ\n",
    "\n",
    "Нормализация и масштабирование признаков — это процесс приведения значений признаков к определённому диапазону или масштабу. Это важная часть предобработки данных в МО, которая может улучшить качество модели.\n",
    "\n",
    "Многие алгоритмы машинного обучения требуют, чтобы все признаки имели одинаковый масштаб, так как некоторые из них могут быть гораздо вариативнее других. Например, если у нас есть признаки «возраст» (от 0 до 100 лет) и «ежемесячный доход» (от 0 до 1 000 000 рублей), то ежемесячный доход будет иметь значительно большую вариативность. Это может привести к тому, что алгоритмы МО будут отдавать большее значение признаку с большей вариативностью.\n",
    "\n",
    "Существует несколько основных методов масштабирования признаков.\n",
    "\n",
    "Нормализация\n",
    "\n",
    "Нормализация (MinMax-нормализация) преобразует значения признаков в диапазон от 0 до 1 или от -1 до 1.\n",
    "\n",
    "Это можно сделать с помощью формулы:\n",
    "\n",
    ", где:\n",
    "\n",
    " — исходное значение;\n",
    "\n",
    " и  — минимальное и максимальное значения в наборе данных;\n",
    "\n",
    " — нормализованное значение.\n",
    "\n",
    "Рассмотрим MinMax-нормализацию на примере числового признака «возраст»:\n",
    "\n",
    "ВОЗРАСТ\tMINMAX-НОРМАЛИЗАЦИЯ\n",
    "20\t0.0000\n",
    "30\t0.3333\n",
    "40\t0.6667\n",
    "50\t1.0000\n",
    "Для каждого значения признака мы вычисляем новое значение, используя формулу, приведённую выше. В этом примере минимальное значение возраста равно 20, а максимальное — 50. Применяя формулу, мы получаем новые значения признака, которые находятся в диапазоне от 0 до 1. Например, возраст 30 будет масштабирован до 0.3333, а возраст 50 — до 1.0000.\n",
    "\n",
    "MinMax-нормализация может быть полезна, когда значения признаков имеют разный масштаб и диапазон значений. Однако необходимо быть осторожным при применении MinMax-нормализации, если выборка содержит выбросы, так как они могут сильно искажать результаты масштабирования. Кроме того, необходимо обрабатывать случаи, когда в тестовой выборке встречаются значения признака, которых не было в обучающей выборке.\n",
    "\n",
    "Стандартизация\n",
    "\n",
    "Стандартизация (L2 масштабирование, Z-оценка) преобразует значения признаков в распределение со средним значением 0 и стандартным отклонением 1.\n",
    "\n",
    "Это можно сделать с помощью формулы:\n",
    "\n",
    ", где:\n",
    "\n",
    " — значение признака;\n",
    "\n",
    " — среднее значение признака в выборке;\n",
    "\n",
    " — стандартное отклонение признака в выборке.\n",
    "\n",
    "Рассмотрим стандартизацию на примере числового признака «возраст»:\n",
    "\n",
    "ВОЗРАСТ\tСТАНДАРТИЗАЦИЯ\n",
    "20\t-1.3416\n",
    "30\t-0.4472\n",
    "40\t0.4472\n",
    "50\t1.3416\n",
    "Для каждого значения признака мы вычисляем новое значение, используя формулу, приведённую выше.\n",
    "\n",
    "В примере среднее значение возраста равно 35, а стандартное отклонение — 12.5. Применяя формулу, мы получаем новые значения признака, которые находятся в стандартном нормальном распределении со средним значением, равным 0, и стандартным отклонением, равным 1. Например, возраст 30 будет масштабирован до -0.4472, а возраст 50 — до 1.3416.\n",
    "\n",
    "Стандартизация может быть полезна, когда значения признаков имеют разный масштаб и диапазон значений, но при этом не содержат выбросы. Стандартизация также может улучшить качество модели, которая использует линейные методы машинного обучения, так как они часто основаны на предположении о стандартном нормальном распределении данных.\n",
    "\n",
    "Выбор метода масштабирования признаков зависит от конкретной задачи и данных. Также важно отметить, что в производственной среде масштабирование признаков следует выполнять только на тренировочных данных, а затем применять те же параметры масштабирования на тестовых данных и новых данных.\n",
    "\n",
    "ПРЕОБРАЗОВАНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ\n",
    "\n",
    "Категориальные признаки (например, цвет, размер, марка автомобиля) — один из типов данных, используемых в машинном обучении. Однако многие алгоритмы машинного обучения работают только с числовыми данными. Поэтому необходимо преобразовать категориальные признаки в числовые. Этот процесс называется кодированием категориальных признаков.\n",
    "\n",
    "Существует несколько методов кодирования категориальных признаков.\n",
    "\n",
    "One-Hot Encoding\n",
    "\n",
    "Этот метод преобразует каждую категориальную переменную в набор бинарных переменных. Для каждого уникального значения переменной создаётся отдельная бинарная переменная. Если переменная принимает значение, равное значению категории, то соответствующая бинарная переменная будет равна 1, в противном случае — 0.\n",
    "\n",
    "Рассмотрим One-Hot Encoding на примере категориального признака «фрукт» с тремя уникальными значениями: яблоко, банан и апельсин.\n",
    "\n",
    "ФРУКТ\tЯБЛОКО\tБАНАН\tАПЕЛЬСИН\n",
    "ЯБЛОКО\t1\t0\t0\n",
    "БАНАН\t0\t1\t0\n",
    "АПЕЛЬСИН\t0\t0\t1\n",
    "Каждый уникальный фрукт превращается в отдельный столбец, значениями в котором могут быть 1 или 0 в зависимости от того, какой фрукт присутствует в конкретном наблюдении. Если в наблюдении присутствуют несколько фруктов, соответствующие столбцы получат значение 1.\n",
    "\n",
    "В приведённом примере первое и последнее наблюдение содержат яблоко, поэтому столбцы «Яблоко» для этих наблюдений имеют значение 1. Второе и четвёртое наблюдение содержат банан, поэтому соответствующий столбец «Банан» имеет значение 1. Третье и шестое наблюдение содержат апельсин, поэтому соответствующий столбец «Апельсин» имеет значение 1.\n",
    "\n",
    "Label Encoding\n",
    "\n",
    "Этот метод присваивает каждому уникальному значению категориальной переменной уникальный целочисленный код.\n",
    "\n",
    "Рассмотрим Label Encoding на примере категориального признака «фрукт» с тремя уникальными значениями: яблоко, банан и апельсин.\n",
    "\n",
    "ФРУКТ\tКОД\n",
    "Яблоко\t1\n",
    "Банан\t2\n",
    "Апельсин\t3\n",
    "Банан\t2\n",
    "Яблоко\t1\n",
    "Апельсин\t3\n",
    "Каждая уникальная категория получает уникальный числовой код. В этом примере яблоко имеет код 1, банан — код 2, а апельсин — код 3.\n",
    "\n",
    "При использовании Label Encoding важно знать, что коды не являются порядковыми. То есть код 2 для банана не означает, что банан в два раза больше яблока. Коды используются только для идентификации категорий.\n",
    "\n",
    "Label Encoding может быть полезен, когда категории обладают некоторой внутренней упорядоченностью: например, признак «образование», где можно использовать порядковые числа для идентификации уровней образования. Однако если категории не обладают внутренней упорядоченностью (например, цвета), то использование Label Encoding может быть менее эффективным.\n",
    "\n",
    "Mean Encoding (также Target Encoding)\n",
    "\n",
    "Этот метод преобразует категориальные признаки в числовые значения, которые представляют среднее значение целевой переменной для каждой категории.\n",
    "\n",
    "Допустим, у нас есть набор данных с категориальным признаком «цвет» и целевой переменной «цена». Мы хотим закодировать категориальный признак «цвет» с помощью Mean Encoding.\n",
    "\n",
    "Посчитаем среднее значение целевой переменной для каждой категории «цвета»:\n",
    "\n",
    "ЦВЕТ\tЦЕНА\n",
    "Красный\t10\n",
    "Зеленый\t20\n",
    "Синий\t30\n",
    "Красный\t15\n",
    "Зеленый\t25\n",
    "Средние значения для каждой категории:\n",
    "\n",
    "ЦВЕТ\tЦЕНА\n",
    "Красный\t12.5\n",
    "Зеленый\t22.5\n",
    "Синий\t30.0\n",
    "Заменим значения категориального признака «цвет» на его средние значения:\n",
    "\n",
    "ЦВЕТ\tЦЕНА\n",
    "Красный\t12.5\n",
    "Зеленый\t22.5\n",
    "Синий\t30.0\n",
    "Красный\t12.5\n",
    "Зеленый\t22.5\n",
    "Таким образом, мы закодировали категориальный признак «цвет» в числовые значения с помощью Mean Encoding, используя информацию о целевой переменной «цена». Это может улучшить точность модели машинного обучения при работе с категориальными признаками.\n",
    "\n",
    "Frequency Encoding\n",
    "\n",
    "Этот метод присваивает каждому уникальному значению категориальной переменной частоту его появления в данных.\n",
    "\n",
    "Рассмотрим Frequency Encoding на примере категориального признака «фрукт» с тремя уникальными значениями: яблоко, банан и апельсин.\n",
    "\n",
    "ФРУКТ\tFREQUENCY ENCODING\n",
    "Яблоко\t0.3333\n",
    "Банан\t0.3333\n",
    "Апельсин\t0.3333\n",
    "Банан\t0.3333\n",
    "Яблоко\t0.3333\n",
    "Апельсин\t0.3333\n",
    "Каждое уникальное значение категориального признака заменяется на частоту его появления в данных. В этом примере все три значения фруктов встречаются по два раза, поэтому их частота равна . В строках, где фрукт повторяется, значения Frequency Encoding остаются одинаковыми.\n",
    "\n",
    "Frequency Encoding может быть полезен, когда категории не имеют внутренней упорядоченности, а частота появления категории в данных может быть связана с целевой переменной. Однако при использовании Frequency Encoding необходимо быть осторожным, чтобы избежать переобучения модели. Кроме того, необходимо обработать случаи, когда в тестовой выборке встречаются значения категориального признака, которых не было в обучающей выборке.\n",
    "\n",
    "В зависимости от исходных данных перечисленные методы можно применять как отдельно, так и в сочетании друг с другом.\n",
    "\n",
    "6. СОЗДАНИЕ НОВЫХ ПРИЗНАКОВ\n",
    "\n",
    "Создание новых признаков (feature engineering) в машинном обучении — это процесс преобразования исходных данных в новые признаки, которые могут улучшить качество модели и её способность к предсказанию.\n",
    "\n",
    "Ниже перечислены некоторые методы создания новых признаков в машинном обучении.\n",
    "\n",
    "Инженерия признаков на основе знаний об отрасли. В этом подходе эксперты отрасли и/или аналитики создают новые признаки на основе своих знаний о предметной области. Это может включать в себя социально-экономические показатели, метеорологические данные, информацию об исторических событиях и т. д.\n",
    "\n",
    "Например, в медицинских данных на основе роста и веса пациента можно создать признак «индекс массы тела» (BMI), используя специальную формулу\n",
    "\n",
    "Преобразование существующих признаков. В этом подходе существующие признаки можно преобразовать в новые с помощью математических операций логарифмирования, возведения в степень, извлечения корня и т. д.\n",
    "\n",
    "Извлечение значений из других признаков. Так, можно извлечь день недели или время из даты и времени.\n",
    "\n",
    "Создание признаков на основе текстов. При анализе текстовых данных новые признаки можно создать, извлекая ключевые слова и фразы, используя стемминг, лемматизацию, CountVectorizer, TF-IDF, BPE, а также методы МО для анализа тональности и определения тем.\n",
    "\n",
    "Создание признаков на основе временных рядов. При анализе временных рядов новые признаки можно создать путём вычисления статистических показателей: скользящего среднего, стандартного отклонения, корреляции и т. д.\n",
    "\n",
    "7. ОТБОР ПРИЗНАКОВ\n",
    "\n",
    "Отбор признаков (feature selection) — это процесс выбора из множества доступных признаков наиболее значимых, которые будут использоваться для обучения модели. Цель отбора признаков — уменьшить размерность данных, устранить шум, повысить точность модели и улучшить её интерпретируемость.\n",
    "\n",
    "Существует несколько методов отбора признаков:\n",
    "\n",
    "Рекурсивное устранение признаков (recursive feature elimination). Алгоритм удаляет признаки с наименьшей важностью для модели, пока не останется необходимое число признаков.\n",
    "Подход на основе важности признаков. Важность признаков для модели определяют с помощью алгоритмов (случайный лес или градиентный бустинг). На основе этого отбирают наиболее важные признаки.\n",
    "Подход на основе корреляции признаков. Признаки, которые сильно коррелируют друг с другом, могут увеличивать сложность модели без улучшения её качества. Поэтому такие признаки удаляют.\n",
    "Важно понимать, что отбор признаков — это процесс, который может повлиять на точность модели. Поэтому необходимо тщательно оценить каждый метод и выбрать наиболее подходящий в конкретной ситуации.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЕАЛИЗАЦИЯ ПОДГОТОВКИ ДАННЫХ В PYTHON\n",
    "В этом юните мы рассмотрели основные этапы подготовки данных для проекта машинного обучения, а именно:\n",
    "\n",
    "Исследование данных: различные методы визуализации и статистические техники.\n",
    "Очистка данных от ошибок и пропусков.\n",
    "Разделение выборки на обучающую и тестовую, которое необходимо выполнить до начала обработки данных и обучения модели.\n",
    "Работа с признаками: работа с выбросами и преобразование признаков.\n",
    "Создание новых признаков — процесс преобразования исходных данных в новые признаки.\n",
    "Отбор признаков — процесс выбора из множества доступных признаков наиболее значимых, которые будут использоваться для обучения модели.\n",
    "В следующем юните мы узнаем, как оценивать качество алгоритмов обучения с учителем."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Оценка качества алгоритмов обучения с учителем\n",
    "Цель занятия — научиться самостоятельно подбирать подходящую метрику качества.\n",
    "\n",
    "Прежде чем начать работать с алгоритмами машинного обучения, давайте разберёмся, как оценивать качество их работы. Это позволит в дальнейшем оценивать все алгоритмы, с которыми мы будем иметь дело. Для этого используются специальные формулы — метрики качества.\n",
    "\n",
    "Метрики качества в машинном обучении нужны для оценки качества работы алгоритмов. Они позволяют сравнивать разные модели машинного обучения и выбирать наилучшую для конкретной задачи. Кроме того, метрики качества позволяют определить, насколько хорошо обученная модель справляется с поставленной перед ней задачей и насколько её результаты достоверны.\n",
    "\n",
    "Метрики качества для задачи классификации позволяют определить, насколько точно модель предсказывает метки классов для тестовых данных, а метрики качества для задачи регрессии — насколько близки предсказанные значения к истинным.\n",
    "\n",
    "Метрики качества можно использовать для выбора оптимального набора гиперпараметров модели, настройки её параметров, а также для сравнения разных алгоритмов машинного обучения и выбора наилучшего из них.\n",
    "\n",
    "Гиперпараметры модели — это параметры, которые определяют до обучения модели. Они регулируют поведение алгоритма обучения: скорость обучения, количество скрытых слоёв в нейронной сети, количество деревьев в случайном лесу и т. д.\n",
    "МЕТРИКИ КАЧЕСТВА РЕГРЕССИИ\n",
    "\n",
    "Метрики качества регрессии — это числовые характеристики, которые используют для оценки того, насколько хорошо модель регрессии соответствует данным.\n",
    "\n",
    "Рассмотрим некоторые из наиболее распространённых метрик качества регрессии с примерами.\n",
    "\n",
    "СРЕДНЕКВАДРАТИЧНАЯ ОШИБКА\n",
    "\n",
    "Среднеквадратичная ошибка (Mean Squared Error, MSE) — это среднее значение квадратов разностей между прогнозируемыми и фактическими значениями.\n",
    "\n",
    "Формула для среднеквадратичной ошибки (MSE):\n",
    "\n",
    ", где:\n",
    "\n",
    " — наблюдаемое значение;\n",
    " — предсказанное значение.\n",
    "MSE особенно часто используют, когда существует линейная зависимость между признаками и целевой переменной. Это происходит, когда мы имеем дело с непрерывными переменными, например, ценой на недвижимость или доходом.\n",
    "\n",
    "Так, если у нас есть модель, которая предсказывает количество продаж в магазине, MSE можно рассчитать как среднее значение квадратов разностей между прогнозируемыми и фактическими продажами.\n",
    "\n",
    "СРЕДНЯЯ АБСОЛЮТНАЯ ОШИБКА\n",
    "\n",
    "Средняя абсолютная ошибка (Mean Absolute Error, MAE) — это среднее значение абсолютных разностей между прогнозируемыми и фактическими значениями.\n",
    "\n",
    "Формула для средней абсолютной ошибки (MAE):\n",
    "\n",
    ", где:\n",
    "\n",
    " — наблюдаемое значение;\n",
    " — предсказанное значение.\n",
    "MAE чаще используется, когда мы имеем дело с выбросами и выбивающимися значениями. Она более устойчива к выбросам, чем MSE.\n",
    "\n",
    "Предположим, что у нас есть модель, которая прогнозирует цены на недвижимость. MAE для этой модели можно рассчитать как среднее значение абсолютных разностей между прогнозируемыми и реальными ценами.\n",
    "\n",
    "ФУНКЦИЯ ПОТЕРЬ ХЬЮБЕРА\n",
    "\n",
    "Функция потерь Хьюбера (Huber loss) — это функция потерь, которая комбинирует свойства среднеквадратичной ошибки (MSE) и средней абсолютной ошибки (MAE) в зависимости от значения отклонения. Её используют для задач регрессии и оптимизации моделей машинного обучения.\n",
    "\n",
    "Формула для функции потерь Хьюбера выглядит следующим образом:\n",
    "\n",
    "е\n",
    "с\n",
    "л\n",
    "и\n",
    "и\n",
    "н\n",
    "а\n",
    "ч\n",
    "е\n",
    "Здесь:\n",
    "\n",
    " — наблюдаемое значение;\n",
    " — предсказанное значение;\n",
    " — параметр для определения порога между квадратичной и линейной потерями.\n",
    "Функция потерь Хьюбера вычисляется как среднее значение потерь для всех примеров. Она более устойчива к выбросам, чем MSE, так как уменьшает вклад выбросов в общую ошибку. При этом она сохраняет свойства MSE, когда отклонение мало, и свойства MAE, когда отклонение большое.\n",
    "\n",
    "Предположим, что у нас есть модель, которая прогнозирует цены на недвижимость. Huber loss для этой модели можно рассчитать как среднее значение функции потерь Хьюбера между прогнозируемыми и реальными ценами. Параметр  можно выбрать в зависимости от того, насколько сильно мы хотим уменьшить влияние выбросов на общую ошибку.\n",
    "\n",
    "Это только некоторые из наиболее распространённых метрик качества регрессии. В зависимости от задачи и данных можно использовать и другие.\n",
    "\n",
    "ОТОБРАЖЕНИЕ МЕТРИК КАЧЕСТВА РЕГРЕССИИ\n",
    "\n",
    "В основе MSE, MAE и функции потерь Хьюбера лежит вычислительный процесс, который учитывает отклонения наблюдений от аппроксимирующей гиперплоскости.\n",
    "\n",
    "img\n",
    "Визуализация вычисления метрик качества регрессии\n",
    "Отображение графика отклонений от аппроксимирующей линии для MSE и MAE позволяет оценить точность модели и выявить наличие систематических ошибок в предсказаниях.\n",
    "\n",
    "Если на графике присутствует какая-то структура или зависимость между отклонениями и значением переменных, это может указывать на недостатки модели и необходимость её улучшения.\n",
    "Если график показывает случайное распределение отклонений вокруг нуля, это свидетельствует о том, что модель хорошо справляется с предсказаниями.\n",
    "МЕТРИКИ КАЧЕСТВА КЛАССИФИКАЦИИ\n",
    "\n",
    "Метрики качества классификации — это числовые характеристики, которые используют для оценки того, насколько хорошо модель классификации соответствует данным.\n",
    "\n",
    "КОНЦЕПЦИЯ TP, TN, FP, FN В МЕТРИКАХ КАЧЕСТВА КЛАССИФИКАЦИИ\n",
    "\n",
    "Для работы с метриками качества классификации необходимо понимать следующие термины:\n",
    "\n",
    "истинно положительное решение — True Positive, TP;\n",
    "истинно отрицательное решение — True Negative, TN;\n",
    "ложноположительное решение — False Positive, FP;\n",
    "ложноотрицательное решение — False Negative, FN.\n",
    "TP, TN, FP, FN — это часто используемые сокращения для обозначения результатов двоичной классификации, где есть два класса: положительный (P) и отрицательный (N).\n",
    "\n",
    "TP — это количество правильно классифицированных положительных примеров (True Positive). Например, если модель должна классифицировать изображения на котов и собак и она правильно классифицирует изображение кота как кота, это будет TP.\n",
    "TN — это количество правильно классифицированных отрицательных примеров (True Negative). Например, если модель должна классифицировать изображения на котов и собак и она правильно классифицирует изображение автомобиля как не являющееся ни котом, ни собакой, это будет TN.\n",
    "FP — это количество неправильно классифицированных положительных примеров (False Positive). Например, если модель должна классифицировать изображения на котов и собак и она неправильно классифицирует изображение собаки как кота, это будет FP.\n",
    "FN — это количество неправильно классифицированных отрицательных примеров (False Negative). Например, если модель должна классифицировать изображения на котов и собак и она неправильно классифицирует изображение кота как не являющееся ни котом, ни собакой, это будет FN.\n",
    "Допустим, у нас есть модель для определения, является письмо спамом или не спамом.\n",
    "\n",
    "TP (True Positive) — это случай, когда письмо не является спамом и модель правильно классифицирует его как не спам.\n",
    "TN (True Negative) — это случай, когда письмо является спамом и модель правильно классифицирует его как спам.\n",
    "FP (False Positive) — это случай, когда письмо является спамом, но модель ошибочно классифицирует его как не спам.\n",
    "FN (False Negative) — это случай, когда письмо не является спамом, но наша модель ошибочно классифицирует его как спам.\n",
    "Эти примеры можно обобщить с помощью матрицы ошибок (Confusion matrix):\n",
    "\n",
    "НАБЛЮДАЕМОЕ ЗНАЧЕНИЕ\n",
    "Не спам\tСпам\n",
    "ПРЕДСКАЗАННОЕ ЗНАЧЕНИЕ\tНе спам\tTP\tFP\n",
    "Спам\tFN\tTN\n",
    "В машинном обучении и статистике используется несколько различных метрик для измерения точности моделей. Рассмотрим основные из них.\n",
    "\n",
    "ACCURACY ДЛЯ БИНАРНОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Accuracy (доля правильных ответов) — это отношение числа правильно классифицированных объектов к общему числу объектов в выборке в задаче бинарной классификации.\n",
    "\n",
    "Accuracy — самая простая метрика, которая вычисляет долю верно классифицированных объектов в общем числе объектов. Её часто используют, чтобы оценить качество работы алгоритмов классификации на сбалансированных классах.\n",
    "\n",
    "Формула для accuracy:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных классов;\n",
    " — количество верно предсказанных отрицательных классов;\n",
    " — количество ложно предсказанных положительных классов;\n",
    " — количество ложно предсказанных отрицательных классов.\n",
    "Рассмотрим два примера задач бинарной классификации для выявления спама: первый пример — описательный, второй — с визуализацией.\n",
    "\n",
    "Пусть у нас есть набор данных, состоящий из 1000 писем, из которых 950 — не спам, а 50 — спам. В этом случае классы не сбалансированы, потому что спама гораздо меньше, чем не спама. Если мы используем accuracy как метрику для оценки качества модели, то в этом случае accuracy может давать искажённые результаты.\n",
    "\n",
    "Допустим, модель предсказывает, что все письма — не спам. Тогда accuracy составит 0.95, что может показаться высокой точностью модели. Однако такая модель совершенно непригодна для решения поставленной задачи, так как её цель — выявление спама и она не сможет правильно классифицировать такие объекты.\n",
    "\n",
    "Рассмотрим второй пример, где спам- и не спам-писем поровну — по 10. Визуализация вычисления метрики accuracy для такого примера:\n",
    "\n",
    "img\n",
    "Визуализация вычисления метрики accuracy для бинарной классификации\n",
    "PRECISION ДЛЯ БИНАРНОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Precision (точность) — это отношение числа верно предсказанных положительных классов к общему числу положительных предсказаний в задаче бинарной классификации.\n",
    "\n",
    "Метрику точности (precision) используют, чтобы оценить качество моделей машинного обучения в задачах классификации. Она позволяет измерять, насколько хорошо модель выделяет объекты определённого класса из общего числа объектов, которые она относит к этому классу.\n",
    "\n",
    "Формула для precision:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных классов;\n",
    " — количество ложно предсказанных положительных классов.\n",
    "Рассмотрим метрику точности (precision) для задачи с выявлением спама. В этом случае точность определяет, какой процент из всех писем, которые модель предсказала как спам, действительно являются спамом.\n",
    "\n",
    "Допустим, модель классифицирует 70 писем как спам и только 50 из них на самом деле являются спамом. Тогда точность будет равна . Это означает, что модель правильно классифицировала 71 % писем, которые она отнесла к классу «спам».\n",
    "\n",
    "Метрика точности позволяет оценить качество работы модели с точки зрения её способности правильно идентифицировать объекты положительного класса (спам в нашем примере). Однако метрика точности может не учитывать количество ложноотрицательных прогнозов — случаев, когда модель не определила письма как спам, но на самом деле они являются спамом.\n",
    "\n",
    "Для полной оценки качества работы модели необходимо рассматривать и другие метрики, такие как recall (полнота) и F1-score.\n",
    "\n",
    "Визуализация вычисления метрики precision для набора из 20 писем:\n",
    "\n",
    "img\n",
    "Визуализация вычисления метрики precision для бинарной классификации\n",
    "RECALL (ПОЛНОТА) ДЛЯ БИНАРНОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Recall (полнота) — это отношение числа верно предсказанных положительных классов к общему числу реальных положительных классов.\n",
    "\n",
    "Метрику полноты recall также используют, чтобы оценить качество моделей машинного обучения в задачах классификации. Она позволяет измерять, насколько хорошо модель распознаёт объекты определённого класса в общем числе объектов, которые принадлежат к этому классу.\n",
    "\n",
    "Формула для recall:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных классов;\n",
    " — количество ложно предсказанных отрицательных классов.\n",
    "Рассмотрим метрику полноты recall для задачи с выявлением спама. В этом случае полнота определяет, какой процент из всех спам-писем модель способна правильно идентифицировать.\n",
    "\n",
    "Допустим, среди 100 спам-писем модель смогла правильно идентифицировать только 50. Тогда полнота будет равна , что означает, что модель правильно распознала только 50 % всех спам-писем.\n",
    "\n",
    "Метрика полноты позволяет оценить качество работы модели с точки зрения её способности правильно идентифицировать все объекты положительного класса, т. е. все спам-письма в нашем примере. Однако метрика полноты может не учитывать количество ложноположительных прогнозов — случаев, когда модель неправильно идентифицирует письма как спам, когда на самом деле они им не являются.\n",
    "\n",
    "Визуализация вычисления метрики recall для примера с 20 письмами:\n",
    "\n",
    "img\n",
    "Визуализация вычисления метрики recall для бинарной классификации\n",
    "F1-МЕРА ДЛЯ БИНАРНОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "F1-score — это мера точности и полноты модели, которая вычисляется как гармоническое среднее точности (precision) и полноты (recall) модели.\n",
    "\n",
    "Формула для F1-score:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных экземпляров положительного класса;\n",
    " — количество ложно предсказанных экземпляров положительного класса;\n",
    " — количество ложно предсказанных экземпляров отрицательного класса.\n",
    "В бинарной классификации 1000 писем алгоритм определяет для каждого письма, является ли оно спамом. Зададим другое распределение: 500 — спам, ещё 500 — не спам.\n",
    "\n",
    "Допустим, алгоритм классификации верно определил 450 спам-писем и 480 не спам-писем: TP = 450, TN = 480, FP = 20, FN = 50.\n",
    "\n",
    "Тогда:\n",
    "\n",
    "Алгоритм показывает высокую точность и полноту, так как значения accuracy, precision, recall и F1-score достаточно высокие (больше 0.9). Это говорит о том, что алгоритм хорошо находит и отличает спам-письма от обычных и его можно использовать для дальнейшей работы с данными.\n",
    "\n",
    "Однако FN (ложноотрицательные результаты) выше, чем FP (ложноположительные результаты). Это может быть проблемой, если ложноотрицательные результаты критичны для данной задачи. В целом можно считать, что для задачи бинарной классификации в определении спама алгоритм получил хорошие результаты.\n",
    "\n",
    "Визуализация вычисления метрики F1 для примера с 20 письмами:\n",
    "\n",
    "img\n",
    "Визуализация вычисления метрики F1 для бинарной классификации\n",
    "МНОГОКЛАССОВАЯ КЛАССИФИКАЦИЯ\n",
    "\n",
    "В целом принцип выбора метрик в задаче многоклассовой классификации совпадает с принципом их выбора в задаче бинарной классификации. Однако в задаче многоклассовой классификации есть несколько модификаций метрик precision, recall и F1: micro, macro и weighted.\n",
    "\n",
    "Модификации micro, macro и weighted главным образом различаются тем, как они учитывают распределение классов:\n",
    "\n",
    "micro учитывает все истинно положительные и ложноположительные примеры;\n",
    "macro не учитывает несбалансированность классов в наборе данных;\n",
    "weighted учитывает несбалансированность классов в наборе данных.\n",
    "Если классы сбалансированы, различные модификации метрик (micro, macro и weighted) в задаче многоклассовой классификации будут показывать практически идентичный результат.\n",
    "\n",
    "Объясним вычисление метрик многоклассовой классификации на следующем примере:\n",
    "\n",
    "img\n",
    "Матрица ошибок\n",
    "Будем считать ответы, двигаясь по сетке слева направо и сверху вниз. Получим такие наборы данных (1 — красный квадрат, 2 — синий круг, 3 — зелёный ромб):\n",
    "\n",
    "Истинные значения = [1, 1, 1, 1, 1, 1, 3, 1, 3, 3, 1, 1, 2, 1, 3, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2]\n",
    "\n",
    "Предсказанные значения = [1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2]\n",
    "\n",
    "Создадим матрицу ошибок для вычисления метрик многоклассовой классификации:\n",
    "\n",
    "img\n",
    "ACCURACY ДЛЯ МНОГОКЛАССОВОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Формулу для accuracy можно использовать и для многоклассовой классификации. Мы просто считаем количество правильно и неправильно классифицированных объектов.\n",
    "\n",
    "По матрице ошибок можно получить значение accuracy (сумма значений по диагоналям / сумма значений по матрице):\n",
    "\n",
    "Accuracy плохо работает на несбалансированных выборках.\n",
    "\n",
    "PRECISION ДЛЯ МНОГОКЛАССОВОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Для одного класса  в задаче многоклассовой классификации precision вычисляется по формуле:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных положительных примеров класса .\n",
    "Micro precision — это метрика, которая вычисляет точность для каждого класса по отдельности, а затем усредняет их с использованием общего числа истинных и ложных положительных и отрицательных ответов по всем классам. Эта метрика подходит для задач, где классы не сбалансированы и модель должна давать одинаковый вес каждому объекту.\n",
    "\n",
    "Формула для micro precision:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных положительных примеров класса .\n",
    "В нашем примере можно вычислить micro precision с помощью матрицы ошибок:\n",
    "\n",
    "Macro precision — это метрика, которая вычисляет точность для каждого класса по отдельности и затем усредняет их. Она не учитывает размеры классов, поэтому подходит для задач, где классы сбалансированы.\n",
    "\n",
    "Формула для macro precision:\n",
    "\n",
    ", где:\n",
    "\n",
    " — точность по классу ;\n",
    " — количество классов в задаче классификации.\n",
    "В нашем примере можно вычислить macro precision с помощью матрицы ошибок:\n",
    "\n",
    "Weighted precision — это метрика, которая вычисляет точность для каждого класса по отдельности и затем усредняет их с использованием весов, пропорциональных размеру каждого класса. Она подходит для задач, где классы не сбалансированы и модель должна учитывать важность каждого класса.\n",
    "\n",
    "Формула для weighted precision:\n",
    "\n",
    ", где:\n",
    "\n",
    " — точность по классу ;\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных положительных примеров класса .\n",
    "В нашем примере можно вычислить weighted precision с помощью матрицы ошибок:\n",
    "\n",
    "RECALL (ПОЛНОТА) ДЛЯ МНОГОКЛАССОВОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Для одного класса  в задаче многоклассовой классификации recall вычисляется по формуле:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных отрицательных примеров класса .\n",
    "Micro recall — это метрика, которая вычисляет полноту для каждого класса по отдельности, а затем усредняет их с использованием общего числа истинных и ложных положительных и отрицательных ответов по всем классам. Она подходит для задач, где классы не сбалансированы и модель должна давать одинаковый вес каждому объекту.\n",
    "\n",
    "Формула для micro recall:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных отрицательных примеров класса .\n",
    "В нашем примере вычислить micro recall можно с помощью матрицы ошибок:\n",
    "\n",
    "Macro recall — это метрика, которая вычисляет полноту для каждого класса по отдельности и затем усредняет их. Она не учитывает размеры классов, поэтому подходит для задач, где классы сбалансированы.\n",
    "\n",
    "Формула для macro recall:\n",
    "\n",
    ", где:\n",
    "\n",
    " — полнота по классу ;\n",
    " — количество классов в задаче классификации.\n",
    "В нашем примере можно вычислить macro recall с помощью матрицы ошибок:\n",
    "\n",
    "Weighted recall — это метрика, которая вычисляет полноту для каждого класса по отдельности и затем усредняет их с использованием весов, пропорциональных размеру каждого класса. Подходит для задач, где классы не сбалансированы и модель должна учитывать важность каждого класса.\n",
    "\n",
    "Формула для weighted recall:\n",
    "\n",
    ", где:\n",
    "\n",
    " — полнота по классу ;\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных отрицательных примеров класса .\n",
    "В нашем примере можно вычислить weighted recall с помощью матрицы ошибок:\n",
    "\n",
    "F1-МЕРА ДЛЯ МНОГОКЛАССОВОЙ КЛАССИФИКАЦИИ\n",
    "\n",
    "Для одного класса  в задаче многоклассовой классификации F1-мера вычисляется по формуле:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество верно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных положительных примеров класса ;\n",
    " — количество ложно предсказанных отрицательных примеров класса .\n",
    "Здесь F1-мера является гармоническим средним между точностью и полнотой для одного класса.\n",
    "\n",
    "Micro F1 — это метрика, которая вычисляет F1-меру для каждого класса по отдельности, а затем усредняет их с использованием общего числа истинных и ложных положительных и отрицательных ответов по всем классам. Подходит для задач, где классы не сбалансированы и модель должна давать одинаковый вес каждому объекту.\n",
    "\n",
    "Формула для micro F1:\n",
    "\n",
    "В нашем примере можно вычислить micro F1 с помощью матрицы ошибок:\n",
    "\n",
    "Macro F1 — это метрика, которая вычисляет F1-меру для каждого класса по отдельности и затем усредняет их. Она не учитывает размеры классов, поэтому подходит для задач, где классы сбалансированы.\n",
    "\n",
    "Формула для macro F1:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество классов;\n",
    "— F1-мера для класса .\n",
    "В нашем примере можно вычислить macro F1 с помощью матрицы ошибок:\n",
    "\n",
    "Weighted F1 — метрика, которая вычисляет F1-меру для каждого класса по отдельности и затем усредняет их с использованием весов, пропорциональных размеру каждого класса. Подходит для задач, где классы не сбалансированы и модель должна учитывать важность каждого класса.\n",
    "\n",
    "Формула для weighted F1:\n",
    "\n",
    ", где:\n",
    "\n",
    " — количество примеров во всей выборке;\n",
    " — доля примеров класса  в выборке.\n",
    "В нашем примере можно вычислить weighted F1 с помощью матрицы ошибок:\n",
    "\n",
    "ОБОБЩАЮЩАЯ СПОСОБНОСТЬ АЛГОРИТМОВ И ПЕРЕОБУЧЕНИЕ\n",
    "\n",
    "Метрики качества — не единственное, что нужно учитывать при оценке работы модели машинного обучения. Ещё одна важная характеристика модели — её обобщающая способность.\n",
    "\n",
    "Обобщающая способность алгоритма МО — это способность алгоритма правильно классифицировать новые, ранее неизвестные данные, которые не использовались при обучении. Она является ключевым показателем качества алгоритма машинного обучения.\n",
    "\n",
    "Переобучение (overfitting) — это явление, когда алгоритм машинного обучения получает очень высокую точность на данных, которые использовались для обучения, но плохо работает на новых данных. При переобучении алгоритм машинного обучения настраивается на шум в данных и пытается «запомнить» обучающие данные, а не выявить общие закономерности.\n",
    "\n",
    "При переобучении график метрик на тренировочном наборе данных будет показывать улучшение в процессе обучения. Однако на тестовом наборе данных график метрик может начать падать после достижения пика или перестать улучшаться. Это будет указывать на то, что модель не обобщает знания на новые данные.\n",
    "\n",
    "img\n",
    "Пример ситуации переобучения\n",
    "Переобучение может возникнуть:\n",
    "\n",
    "если модель слишком сложная и содержит слишком много параметров, которые могут настраиваться на шум в данных;\n",
    "обучающая выборка слишком мала или недостаточно разнообразна.\n",
    "Есть несколько методов, которые позволяют предотвратить переобучение. Один из них — регуляризация, о которой мы поговорим в следующем модуле."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЕАЛИЗАЦИЯ ОЦЕНКИ КАЧЕСТВА АЛГОРИТМОВ ОБУЧЕНИЯ С УЧИТЕЛЕМ В PYTHON\n",
    "В этом юните мы рассмотрели метрики, с помощью которых можно оценить качество работы алгоритмов обучения с учителем.\n",
    "\n",
    "Основные метрики качества для задач регрессии:\n",
    "\n",
    "Среднеквадратичная ошибка (MSE).\n",
    "Средняя абсолютная ошибка (MAE).\n",
    "Функция потерь Хьюбера.\n",
    "Основные метрики качества для задач классификации:\n",
    "\n",
    "Доля правильных ответов (Accuracy).\n",
    "Точность (Precision).\n",
    "Полнота (Recall).\n",
    "F1-мера (F1-score).\n",
    "Выбор метрик зависит от конкретной задачи и её целей.\n",
    "\n",
    "Обобщающая способность алгоритмов машинного обучения означает их способность обобщать знания из тренировочных данных и применять их для эффективного решения новых задач на новых данных. То есть хорошо обученная модель должна показывать высокое качество предсказаний не только на тренировочных данных, но и на тестовых и реальных.\n",
    "\n",
    "Однако при обучении модели можно столкнуться с проблемой переобучения, когда модель слишком точно подстроилась под тренировочные данные и её способность к обобщению снизилась. Такая модель показывает плохие результаты на тестовых данных, и её нельзя использовать для решения новых задач.\n",
    "\n",
    "Чтобы избежать переобучения, необходимо использовать специальные техники, такие как регуляризация.\n",
    "\n",
    "В этом модуле нам осталось изучить лишь метод ближайших соседей — один из простейших алгоритмов МО. Прежде чем приступить, давайте закрепим полученные в этом юните знания небольшим тестом."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
